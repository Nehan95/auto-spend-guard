#!/usr/bin/env python3
"""
Test script for Latency Tracking in LangGraph Workflow
Demonstrates performance monitoring capabilities
"""

from langgraph_workflow import SpendAnalyzerWorkflow

def test_latency_tracking():
    """Test the latency tracking functionality"""
    print("üß™ TESTING LATENCY TRACKING IN LANGRAPH WORKFLOW")
    print("=" * 60)
    
    try:
        # Initialize workflow
        workflow = SpendAnalyzerWorkflow()
        print("‚úÖ Workflow initialized successfully!")
        
        # Test question to trigger the workflow
        test_question = "What are our AWS costs and which services are most expensive?"
        print(f"\nüìù Test Question: {test_question}")
        print("-" * 50)
        
        # Run the workflow
        print("üöÄ Running workflow with latency tracking...")
        result = workflow.run({
            "question": test_question
        })
        
        print("\n‚úÖ Workflow completed successfully!")
        
        # Display latency metrics
        if hasattr(workflow, 'display_latency_metrics'):
            workflow.display_latency_metrics(result)
        else:
            print("\nüìä Latency metrics available in result:")
            if "latency_metrics" in result:
                print(f"   ‚Ä¢ Question Classification: {result['latency_metrics'].get('question_classification', {}).get('total_duration_seconds', 0)}s")
                print(f"   ‚Ä¢ Data Retrieval: {result['latency_metrics'].get('data_retrieval', {}).get('total_duration_seconds', 0)}s")
                print(f"   ‚Ä¢ Response Generation: {result['latency_metrics'].get('response_generation', {}).get('total_duration_seconds', 0)}s")
            else:
                print("   ‚Ä¢ No latency metrics found in result")
        
        print("\n" + "="*60)
        print("üéâ Latency tracking test completed!")
        print("\nüöÄ Performance Monitoring Features:")
        print("   ‚Ä¢ Real-time latency tracking for each workflow step")
        print("   ‚Ä¢ LLM vs. overhead timing breakdown")
        print("   ‚Ä¢ Agent performance metrics")
        print("   ‚Ä¢ Response generation timing")
        print("   ‚Ä¢ Comprehensive performance summary")
        
    except Exception as e:
        print(f"‚ùå Error testing latency tracking: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_latency_tracking()
